Distributed Training 
at a Glance

What are the two main reasons for distributing the training process?
A. Reliability and performance improvement.
B. Leak of memory and power consumption.
C. Power consumption and performance improvement.
D. Leak of memory and performance improvement.
2. Which are the two main parallel strategies to distribute the training process?
A. Model and data parallelism.
B. Model and hardware parallelism.
C. Hardware and data parallelism.
D. Software and hardware parallelism.
3. Which paradigm is used by the model parallelism approach?
A. Inter-model.
B. Inter-data.
C. Inter-operation.
D. Inter-parameter.
4. What does the intra-operation paradigm process in parallel?
A. Distinct operations.
B. Parts of the same operation
Layers of the model.
D. Dataset samples.
5. Besides the parameter server, what other synchronization approach is used by the data 
parallelism strategy?
A. All-operations.
B. All-gather.
C. All-reduce.
D. All-scather.
6. What is the first step of executing distributed training in PyTorch?
A. Initialize the communication group.
B. Initialize the model replica.
C. Initialize the data loader.
D. Initialize the container environment.
7. In the context of distributed training in PyTorch, which component is used to put the distributed 
process on the road?
A. Execution library.
B. Communication backend.
C. Program launcher.
D. Compiler backend
PyTorch supports which of the following as a communication backend?
A. NDL.
B. MPI.
C. AMP.
D. NNI.
