{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a20732e-6c90-418a-9817-4c1b4e2a2077",
   "metadata": {
    "id": "5a20732e-6c90-418a-9817-4c1b4e2a2077",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f92994f-ffe8-4e80-9c46-8963aade1246",
   "metadata": {
    "id": "0f92994f-ffe8-4e80-9c46-8963aade1246",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_data_loader(data_dir, batch_size, random_seed=42, valid_size=0.1, shuffle=True, test=False):\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    train_dataset = datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    valid_dataset = datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "  \n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return (train_loader, valid_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d745f184-7704-4850-9f57-4268cf20102e",
   "metadata": {
    "id": "d745f184-7704-4850-9f57-4268cf20102e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader, valid_loader, num_epochs, criterion, optimizer, device):\n",
    "    total_steps = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for step, (images, labels) in enumerate(train_loader):  \n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print ('Step [{}/{}], Loss: {:.4f}'.format(step+1, total_steps, loss.item()))\n",
    "               \n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e811ffaf-11fb-4a57-b16e-595338a32081",
   "metadata": {
    "id": "e811ffaf-11fb-4a57-b16e-595338a32081",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "    \n",
    "    print('Accuracy of the network on the {} validation images: {:.2f} %'.format(5000, 100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1843b38-0eff-476b-8ed0-2a1646dbb72f",
   "metadata": {
    "id": "e1843b38-0eff-476b-8ed0-2a1646dbb72f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce883513-47bf-45b0-b902-807dc848c733",
   "metadata": {
    "id": "ce883513-47bf-45b0-b902-807dc848c733",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    parameters = list(model.parameters())\n",
    "    total_parms = sum([np.prod(p.size()) for p in parameters if p.requires_grad])\n",
    "    return total_parms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d_gHdGv84ocR",
   "metadata": {
    "id": "d_gHdGv84ocR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "\n",
    "        self.fc1 = nn.Linear(64*7*7, 512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "76056f95-3978-44e4-94a0-a9c4c7ee21fc",
   "metadata": {
    "id": "76056f95-3978-44e4-94a0-a9c4c7ee21fc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General parameters\n",
    "data_dir = '/tmp'\n",
    "device = 'cpu'\n",
    "num_classes = 10\n",
    "\n",
    "# Hyperparameters\n",
    "max_lr = 0.00001\n",
    "weight_decay = 0.005\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam\n",
    "\n",
    "# FashionMNIST dataset \n",
    "train_loader, valid_loader, test_loader = build_data_loader(data_dir=data_dir, batch_size=batch_size)\n",
    "\n",
    "# Model definition\n",
    "model = CNN()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optimizer(model.parameters(), max_lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3a2d947-887b-4d3d-9ac0-bb6321f206d9",
   "metadata": {
    "id": "c3a2d947-887b-4d3d-9ac0-bb6321f206d9",
    "outputId": "87219b72-d275-482d-f805-3ab08da2205c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1758858\n"
     ]
    }
   ],
   "source": [
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db1b0241-6c87-40cf-8e55-d8cddf5cc71e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db1b0241-6c87-40cf-8e55-d8cddf5cc71e",
    "outputId": "4e39020b-7a35-4bf0-e2c4-d862cb3257f9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.7138\n",
      "Epoch [2/5], Loss: 0.5603\n",
      "Epoch [3/5], Loss: 0.4461\n",
      "Epoch [4/5], Loss: 0.6135\n",
      "Epoch [5/5], Loss: 0.4535\n",
      "Accuracy of the network on the 10000 test images: 80.25 %\n",
      "CPU times: user 12min 42s, sys: 41 s, total: 13min 23s\n",
      "Wall time: 51.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train the model\n",
    "train(model, train_loader, valid_loader, num_epochs, criterion, optimizer, device)\n",
    "test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e794d3a5-5955-4657-b191-b4b2c2b71b8b",
   "metadata": {
    "id": "e794d3a5-5955-4657-b191-b4b2c2b71b8b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "         aten::mkldnn_convolution        44.01%       1.264ms        44.60%       1.281ms     640.500us             2  \n",
      "    aten::max_pool2d_with_indices        30.01%     862.000us        30.01%     862.000us     431.000us             2  \n",
      "                      aten::addmm        13.68%     393.000us        14.52%     417.000us     208.500us             2  \n",
      "                  aten::clamp_min         6.96%     200.000us         6.96%     200.000us     100.000us             2  \n",
      "                aten::convolution         1.18%      34.000us        46.27%       1.329ms     664.500us             2  \n",
      "                      aten::copy_         0.70%      20.000us         0.70%      20.000us      10.000us             2  \n",
      "                       aten::relu         0.59%      17.000us         7.56%     217.000us     108.500us             2  \n",
      "               aten::_convolution         0.49%      14.000us        45.09%       1.295ms     647.500us             2  \n",
      "                      aten::empty         0.35%      10.000us         0.35%      10.000us       2.500us             4  \n",
      "             aten::_reshape_alias         0.31%       9.000us         0.31%       9.000us       9.000us             1  \n",
      "                          aten::t         0.31%       9.000us         0.49%      14.000us       7.000us             2  \n",
      "                     aten::conv2d         0.24%       7.000us        46.52%       1.336ms     668.000us             2  \n",
      "                aten::as_strided_         0.24%       7.000us         0.24%       7.000us       3.500us             2  \n",
      "                    aten::reshape         0.21%       6.000us         0.52%      15.000us      15.000us             1  \n",
      "                     aten::linear         0.21%       6.000us        15.22%     437.000us     218.500us             2  \n",
      "                 aten::max_pool2d         0.17%       5.000us        30.19%     867.000us     433.500us             2  \n",
      "                     aten::expand         0.14%       4.000us         0.14%       4.000us       2.000us             2  \n",
      "                  aten::transpose         0.10%       3.000us         0.17%       5.000us       2.500us             2  \n",
      "                 aten::as_strided         0.07%       2.000us         0.07%       2.000us       0.500us             4  \n",
      "               aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us             4  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.872ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-02 16:43:31 105274:105274 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-02 16:43:31 105274:105274 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-02 16:43:31 105274:105274 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "schedule = torch.profiler.schedule(wait=5, warmup=5, active=3)\n",
    "\n",
    "#prof = profile(schedule=schedule, activities=[ProfilerActivity.CPU], with_stack=True, record_shapes=True, on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/cnn/'))\n",
    "prof = profile(activities=[ProfilerActivity.CPU])\n",
    "        \n",
    "input_sample, _ = next(iter(train_loader))\n",
    "\n",
    "prof.start()\n",
    "model(input_sample)\n",
    "prof.stop()\n",
    "\n",
    "#prof.export_chrome_trace(\"./cnn_trace.json\")\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "409a126c-15ba-4977-8fac-014f796accca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_names = ['input']\n",
    "output_names = ['output']\n",
    "torch.onnx.export(model, input_sample, \"cnn.onnx\", input_names=input_names, output_names=output_names, export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32614736-498a-423a-a757-630299962db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
