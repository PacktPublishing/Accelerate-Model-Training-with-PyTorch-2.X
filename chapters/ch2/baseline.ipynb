{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a20732e-6c90-418a-9817-4c1b4e2a2077",
   "metadata": {
    "id": "5a20732e-6c90-418a-9817-4c1b4e2a2077",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f92994f-ffe8-4e80-9c46-8963aade1246",
   "metadata": {
    "id": "0f92994f-ffe8-4e80-9c46-8963aade1246",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_data_loader(data_dir, batch_size, random_seed=42, valid_size=0.1, shuffle=True, test=False):\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    train_dataset = datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    valid_dataset = datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "  \n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return (train_loader, valid_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d745f184-7704-4850-9f57-4268cf20102e",
   "metadata": {
    "id": "d745f184-7704-4850-9f57-4268cf20102e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader, valid_loader, num_epochs, criterion, optimizer, device):\n",
    "    total_steps = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        for step, (images, labels) in enumerate(train_loader):  \n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "        \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print ('Step [{}/{}], Loss: {:.4f}'.format(step+1, total_steps, loss.item()))\n",
    "               \n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e811ffaf-11fb-4a57-b16e-595338a32081",
   "metadata": {
    "id": "e811ffaf-11fb-4a57-b16e-595338a32081",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in valid_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "    \n",
    "    print('Accuracy of the network on the {} validation images: {:.2f} %'.format(5000, 100 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1843b38-0eff-476b-8ed0-2a1646dbb72f",
   "metadata": {
    "id": "e1843b38-0eff-476b-8ed0-2a1646dbb72f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce883513-47bf-45b0-b902-807dc848c733",
   "metadata": {
    "id": "ce883513-47bf-45b0-b902-807dc848c733",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    parameters = list(model.parameters())\n",
    "    total_parms = sum([np.prod(p.size()) for p in parameters if p.requires_grad])\n",
    "    return total_parms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d_gHdGv84ocR",
   "metadata": {
    "id": "d_gHdGv84ocR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "\n",
    "        self.fc1 = nn.Linear(64*7*7, 512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76056f95-3978-44e4-94a0-a9c4c7ee21fc",
   "metadata": {
    "id": "76056f95-3978-44e4-94a0-a9c4c7ee21fc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1630090\n"
     ]
    }
   ],
   "source": [
    "# General parameters\n",
    "data_dir = '/tmp'\n",
    "device = 'cpu'\n",
    "num_classes = 10\n",
    "\n",
    "# Hyperparameters\n",
    "max_lr = 0.00001\n",
    "weight_decay = 0.005\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam\n",
    "\n",
    "# FashionMNIST dataset \n",
    "train_loader, valid_loader, test_loader = build_data_loader(data_dir=data_dir, batch_size=batch_size)\n",
    "\n",
    "# Model definition\n",
    "model = CNN()\n",
    "print(count_parameters(model))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optimizer(model.parameters(), max_lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db1b0241-6c87-40cf-8e55-d8cddf5cc71e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db1b0241-6c87-40cf-8e55-d8cddf5cc71e",
    "outputId": "4e39020b-7a35-4bf0-e2c4-d862cb3257f9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7775\n",
      "Epoch [2/10], Loss: 0.6085\n",
      "Epoch [3/10], Loss: 0.5379\n",
      "Epoch [4/10], Loss: 0.5832\n",
      "Epoch [5/10], Loss: 0.4818\n",
      "Epoch [6/10], Loss: 0.4938\n",
      "Epoch [7/10], Loss: 0.5739\n",
      "Epoch [8/10], Loss: 0.4474\n",
      "Epoch [9/10], Loss: 0.4864\n",
      "Epoch [10/10], Loss: 0.4826\n",
      "CPU times: user 34min 6s, sys: 3min 1s, total: 37min 7s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(model, train_loader, valid_loader, num_epochs, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7bccde2-82ec-4413-b36d-3244cf945266",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 83.8 %\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e794d3a5-5955-4657-b191-b4b2c2b71b8b",
   "metadata": {
    "id": "e794d3a5-5955-4657-b191-b4b2c2b71b8b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                      aten::addmm        36.08%       1.406ms        36.93%       1.439ms     719.500us             2  \n",
      "         aten::mkldnn_convolution        32.85%       1.280ms        33.44%       1.303ms     651.500us             2  \n",
      "    aten::max_pool2d_with_indices        22.86%     891.000us        22.86%     891.000us     445.500us             2  \n",
      "                  aten::clamp_min         3.05%     119.000us         3.05%     119.000us      59.500us             2  \n",
      "                aten::convolution         0.92%      36.000us        34.85%       1.358ms     679.000us             2  \n",
      "                      aten::copy_         0.64%      25.000us         0.64%      25.000us      12.500us             2  \n",
      "               aten::_convolution         0.49%      19.000us        33.92%       1.322ms     661.000us             2  \n",
      "                       aten::relu         0.49%      19.000us         3.54%     138.000us      69.000us             2  \n",
      "                     aten::linear         0.49%      19.000us        37.90%       1.477ms     738.500us             2  \n",
      "                      aten::empty         0.36%      14.000us         0.36%      14.000us       3.500us             4  \n",
      "                          aten::t         0.28%      11.000us         0.49%      19.000us       9.500us             2  \n",
      "             aten::_reshape_alias         0.26%      10.000us         0.26%      10.000us      10.000us             1  \n",
      "                aten::as_strided_         0.23%       9.000us         0.23%       9.000us       4.500us             2  \n",
      "                     aten::conv2d         0.21%       8.000us        35.05%       1.366ms     683.000us             2  \n",
      "                 aten::max_pool2d         0.21%       8.000us        23.07%     899.000us     449.500us             2  \n",
      "                    aten::reshape         0.18%       7.000us         0.44%      17.000us      17.000us             1  \n",
      "                     aten::expand         0.18%       7.000us         0.21%       8.000us       4.000us             2  \n",
      "                  aten::transpose         0.13%       5.000us         0.21%       8.000us       4.000us             2  \n",
      "                 aten::as_strided         0.10%       4.000us         0.10%       4.000us       1.000us             4  \n",
      "               aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us             4  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.897ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-05-13 18:34:14 2164910:2164910 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-05-13 18:34:14 2164910:2164910 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-05-13 18:34:14 2164910:2164910 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "schedule = torch.profiler.schedule(wait=5, warmup=5, active=3)\n",
    "\n",
    "#prof = profile(schedule=schedule, activities=[ProfilerActivity.CPU], with_stack=True, record_shapes=True, on_trace_ready=torch.profiler.tensorboard_trace_handler('./log/cnn/'))\n",
    "prof = profile(activities=[ProfilerActivity.CPU])\n",
    "        \n",
    "input_sample, _ = next(iter(train_loader))\n",
    "\n",
    "prof.start()\n",
    "model(input_sample)\n",
    "prof.stop()\n",
    "\n",
    "#prof.export_chrome_trace(\"./cnn_trace.json\")\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "409a126c-15ba-4977-8fac-014f796accca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== Diagnostic Run torch.onnx.export version 2.0.0+cpu ==============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_names = ['input']\n",
    "output_names = ['output']\n",
    "torch.onnx.export(model, input_sample, \"cnn.onnx\", input_names=input_names, output_names=output_names, export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32614736-498a-423a-a757-630299962db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
